{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8810b8e",
   "metadata": {},
   "source": [
    "## Consolidate Financial and Macroeconomic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcff6b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Master DataFrame created successfully!\n",
      "Shape of the data: (2577, 12)\n",
      "\n",
      "Column names:\n",
      "['sp500_Open', 'sp500_High', 'sp500_Low', 'sp500_Close', 'sp500_Volume', 'nasdaq_Close', 'nasdaq_Volume', 'ftse100_Close', 'ftse100_Volume', 'macro_inflation', 'macro_unemployment', 'macro_vix']\n",
      "\n",
      "First 5 rows:\n",
      "             sp500_Open   sp500_High    sp500_Low  sp500_Close  sp500_Volume  \\\n",
      "Date                                                                           \n",
      "2015-04-01  2067.629883  2067.629883  2048.379883  2059.689941    3543270000   \n",
      "2015-04-02  2060.030029  2072.169922  2057.320068  2066.959961    3095960000   \n",
      "2015-04-06  2064.870117  2086.989990  2056.520020  2080.620117    3302970000   \n",
      "2015-04-07  2080.790039  2089.810059  2076.100098  2076.330078    3065510000   \n",
      "2015-04-08  2076.939941  2086.689941  2073.300049  2081.899902    3265330000   \n",
      "\n",
      "            nasdaq_Close  nasdaq_Volume  ftse100_Close  ftse100_Volume  \\\n",
      "Date                                                                     \n",
      "2015-04-01   4880.229980     1874960000    6809.500000     800482200.0   \n",
      "2015-04-02   4886.939941     1563670000    6833.500000     575894800.0   \n",
      "2015-04-06   4917.319824     1737560000    6936.139844     678462400.0   \n",
      "2015-04-07   4910.229980     1572940000    6961.799805     704104300.0   \n",
      "2015-04-08   4950.819824     1714210000    6937.399902     865524000.0   \n",
      "\n",
      "            macro_inflation  macro_unemployment  macro_vix  \n",
      "Date                                                        \n",
      "2015-04-01          236.222                 5.4      15.11  \n",
      "2015-04-02          236.222                 5.4      14.67  \n",
      "2015-04-06          236.222                 5.4      14.74  \n",
      "2015-04-07          236.222                 5.4      14.78  \n",
      "2015-04-08          236.222                 5.4      13.98  \n",
      "\n",
      "Last 5 rows:\n",
      "             sp500_Open   sp500_High    sp500_Low  sp500_Close  sp500_Volume  \\\n",
      "Date                                                                           \n",
      "2025-06-24  6061.209961  6101.759766  6059.250000  6092.180176    5443690000   \n",
      "2025-06-25  6104.229980  6108.509766  6080.089844  6092.160156    5171110000   \n",
      "2025-06-26  6112.089844  6146.520020  6107.270020  6141.020020    5308140000   \n",
      "2025-06-27  6150.700195  6187.680176  6132.350098  6173.069824    7889350000   \n",
      "2025-06-30  6193.359863  6215.080078  6174.970215  6204.950195    5782900000   \n",
      "\n",
      "            nasdaq_Close  nasdaq_Volume  ftse100_Close  ftse100_Volume  \\\n",
      "Date                                                                     \n",
      "2025-06-24  19912.529297     8330090000    8759.000000    1.063635e+09   \n",
      "2025-06-25  19973.550781     8256120000    8718.799805    6.993024e+08   \n",
      "2025-06-26  20167.910156     8383380000    8735.599609    7.684350e+08   \n",
      "2025-06-27  20273.460938    10951070000    8798.900391    7.115221e+08   \n",
      "2025-06-30  20369.730469     8220420000    8761.000000    7.133043e+08   \n",
      "\n",
      "            macro_inflation  macro_unemployment  macro_vix  \n",
      "Date                                                        \n",
      "2025-06-24           320.58                 4.2      17.48  \n",
      "2025-06-25           320.58                 4.2      16.76  \n",
      "2025-06-26           320.58                 4.2      16.59  \n",
      "2025-06-27           320.58                 4.2      16.32  \n",
      "2025-06-30           320.58                 4.2      16.32  \n",
      "\n",
      "Data types:\n",
      "sp500_Open            float64\n",
      "sp500_High            float64\n",
      "sp500_Low             float64\n",
      "sp500_Close           float64\n",
      "sp500_Volume            int64\n",
      "nasdaq_Close          float64\n",
      "nasdaq_Volume           int64\n",
      "ftse100_Close         float64\n",
      "ftse100_Volume        float64\n",
      "macro_inflation       float64\n",
      "macro_unemployment    float64\n",
      "macro_vix             float64\n",
      "dtype: object\n",
      "\n",
      "Date range:\n",
      "From: 2015-04-01 00:00:00 To: 2025-06-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_FOLDER = \"data\"\n",
    "FINANCIAL_FILES = {\n",
    "    'sp500': os.path.join(DATA_FOLDER, 's&p_500_daily.csv'),\n",
    "    'nasdaq': os.path.join(DATA_FOLDER, 'nasdaq_daily.csv'),\n",
    "    'ftse100': os.path.join(DATA_FOLDER, 'ftse_100_daily.csv')\n",
    "}\n",
    "MACRO_FILES = {\n",
    "    #'gdp': os.path.join(DATA_FOLDER, 'macro_gdp.csv'),\n",
    "    'inflation': os.path.join(DATA_FOLDER, 'macro_inflation_cpi.csv'),\n",
    "    'unemployment': os.path.join(DATA_FOLDER, 'macro_unemploymentrate.csv'),\n",
    "    'vix': os.path.join(DATA_FOLDER, 'macro_vix.csv')\n",
    "}\n",
    "\n",
    "# --- Load and Combine Data ---\n",
    "\n",
    "# Load the primary financial index (e.g., S&P 500)\n",
    "# The CSV structure: Row 1=headers, Row 2=tickers, Row 3=Date placeholder, Row 4+=data\n",
    "# We need to skip rows 1 and 2, then use column 0 (Price) as the date index\n",
    "df_master = pd.read_csv(FINANCIAL_FILES['sp500'], skiprows=[1, 2], index_col=0, parse_dates=True)\n",
    "\n",
    "# Rename the index to something more meaningful\n",
    "df_master.index.name = 'Date'\n",
    "\n",
    "# Select and rename key columns to avoid confusion\n",
    "df_master = df_master[['Open', 'High', 'Low', 'Close', 'Volume']].add_prefix('sp500_')\n",
    "\n",
    "# Load and merge other financial indices\n",
    "for name, path in FINANCIAL_FILES.items():\n",
    "    if name != 'sp500':\n",
    "        df_temp = pd.read_csv(path, skiprows=[1, 2], index_col=0, parse_dates=True)\n",
    "        df_temp.index.name = 'Date'\n",
    "        df_master = df_master.merge(\n",
    "            df_temp[['Close', 'Volume']].add_prefix(f'{name}_'),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "# Load and merge macroeconomic data\n",
    "for name, path in MACRO_FILES.items():\n",
    "    try:\n",
    "        df_macro = pd.read_csv(path, index_col='DATE', parse_dates=True)\n",
    "        # Rename the column to be specific\n",
    "        df_macro.rename(columns={df_macro.columns[0]: f'macro_{name}'}, inplace=True)\n",
    "        df_master = df_master.merge(df_macro, left_index=True, right_index=True, how='left')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {path} not found, skipping {name} data\")\n",
    "\n",
    "# --- Clean and Preprocess ---\n",
    "\n",
    "# Forward-fill the macroeconomic data to fill daily gaps\n",
    "macro_cols = [col for col in df_master.columns if 'macro_' in col]\n",
    "if macro_cols:\n",
    "    df_master[macro_cols] = df_master[macro_cols].ffill()\n",
    "\n",
    "# Use interpolation for any remaining gaps (e.g., in stock data on holidays)\n",
    "df_master.interpolate(method='time', inplace=True)\n",
    "\n",
    "# Drop any rows that still have missing values (typically at the very beginning)\n",
    "df_master.dropna(inplace=True)\n",
    "\n",
    "print(\"‚úÖ Master DataFrame created successfully!\")\n",
    "print(\"Shape of the data:\", df_master.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(df_master.columns.tolist())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_master.head())\n",
    "print(\"\\nLast 5 rows:\")\n",
    "print(df_master.tail())\n",
    "print(\"\\nData types:\")\n",
    "print(df_master.dtypes)\n",
    "print(\"\\nDate range:\")\n",
    "print(f\"From: {df_master.index.min()} To: {df_master.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adf4df9",
   "metadata": {},
   "source": [
    "## Final Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae7a0b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL DATASET SUMMARY\n",
      "============================================================\n",
      "üìä Dataset Shape: 2,577 rows √ó 12 columns\n",
      "üìÖ Date Range: 2015-04-01 to 2025-06-30\n",
      "‚è±Ô∏è  Duration: 3,743 days\n",
      "\n",
      "üìà Data Categories:\n",
      "  ‚Ä¢ Financial Data: 9 columns\n",
      "  ‚Ä¢ Macroeconomic Data: 3 columns\n",
      "\n",
      "üîç Data Quality Check:\n",
      "  ‚Ä¢ Total missing values: 0\n",
      "  ‚Ä¢ Rows with any missing values: 0\n",
      "\n",
      "üìã Column Summary:\n",
      "   1. sp500_Open           - Missing:    0 (0.0%)\n",
      "   2. sp500_High           - Missing:    0 (0.0%)\n",
      "   3. sp500_Low            - Missing:    0 (0.0%)\n",
      "   4. sp500_Close          - Missing:    0 (0.0%)\n",
      "   5. sp500_Volume         - Missing:    0 (0.0%)\n",
      "   6. nasdaq_Close         - Missing:    0 (0.0%)\n",
      "   7. nasdaq_Volume        - Missing:    0 (0.0%)\n",
      "   8. ftse100_Close        - Missing:    0 (0.0%)\n",
      "   9. ftse100_Volume       - Missing:    0 (0.0%)\n",
      "  10. macro_inflation      - Missing:    0 (0.0%)\n",
      "  11. macro_unemployment   - Missing:    0 (0.0%)\n",
      "  12. macro_vix            - Missing:    0 (0.0%)\n",
      "\n",
      "‚úÖ Dataset is ready for modeling and analysis!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final verification and summary of the consolidated dataset\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"üìä Dataset Shape: {df_master.shape[0]:,} rows √ó {df_master.shape[1]} columns\")\n",
    "print(f\"üìÖ Date Range: {df_master.index.min().strftime('%Y-%m-%d')} to {df_master.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"‚è±Ô∏è  Duration: {(df_master.index.max() - df_master.index.min()).days:,} days\")\n",
    "\n",
    "print(\"\\nüìà Data Categories:\")\n",
    "financial_cols = [col for col in df_master.columns if any(x in col for x in ['sp500', 'nasdaq', 'ftse'])]\n",
    "macro_cols = [col for col in df_master.columns if 'macro_' in col]\n",
    "# sentiment_cols = [col for col in df_master.columns if 'gdelt' in col]\n",
    "\n",
    "print(f\"  ‚Ä¢ Financial Data: {len(financial_cols)} columns\")\n",
    "print(f\"  ‚Ä¢ Macroeconomic Data: {len(macro_cols)} columns\") \n",
    "#print(f\"  ‚Ä¢ Sentiment Data: {len(sentiment_cols)} columns\")\n",
    "\n",
    "print(\"\\nüîç Data Quality Check:\")\n",
    "print(f\"  ‚Ä¢ Total missing values: {df_master.isnull().sum().sum()}\")\n",
    "print(f\"  ‚Ä¢ Rows with any missing values: {df_master.isnull().any(axis=1).sum()}\")\n",
    "\n",
    "print(\"\\nüìã Column Summary:\")\n",
    "for i, col in enumerate(df_master.columns, 1):\n",
    "    missing = df_master[col].isnull().sum()\n",
    "    print(f\"  {i:2}. {col:<20} - Missing: {missing:4} ({missing/len(df_master)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset is ready for modeling and analysis!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb20557b",
   "metadata": {},
   "source": [
    "## Create Time-Series & Crisis Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaec9906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Time-series and crisis features added!\n",
      "Number of crisis days labeled: 499\n",
      "\n",
      "üìÖ FULL DATASET DATE RANGE:\n",
      "   Start: 2015-06-24\n",
      "   End: 2025-06-30\n",
      "   Total days: 2,519\n",
      "\n",
      "üîç FIRST 3 ROWS (earliest dates):\n",
      "            sp500_Close  is_crisis\n",
      "Date                              \n",
      "2015-06-24  2108.580078          1\n",
      "2015-06-25  2102.310059          1\n",
      "2015-06-26  2101.489990          1\n",
      "\n",
      "üîç LAST 3 ROWS (latest dates):\n",
      "            sp500_Close  is_crisis\n",
      "Date                              \n",
      "2025-06-26  6141.020020          0\n",
      "2025-06-27  6173.069824          0\n",
      "2025-06-30  6204.950195          0\n",
      "\n",
      "üìä CRISIS PERIOD BREAKDOWN:\n",
      "   2015_China_Market_Crash: 0 days (2015-06-15 to 2016-02-11)\n",
      "   2018_Volatility: 63 days (2018-10-01 to 2018-12-31)\n",
      "   COVID_Crash: 24 days (2020-02-19 to 2020-03-23)\n",
      "   2022_Inflation_Crash: 0 days (2022-01-01 to 2022-12-31)\n",
      "\n",
      "üìà TOTAL CRISIS vs NON-CRISIS DAYS:\n",
      "   Non-Crisis (0): 2,020 days\n",
      "   Crisis (1): 499 days\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This assumes your master dataframe is named df_master\n",
    "\n",
    "# --- Create Time-Series Features ---\n",
    "# Moving Averages for the S&P 500 close price\n",
    "df_master['sp500_ma_7'] = df_master['sp500_Close'].rolling(window=7).mean()\n",
    "df_master['sp500_ma_30'] = df_master['sp500_Close'].rolling(window=30).mean()\n",
    "\n",
    "# Lagged Values for the S&P 500 close price\n",
    "for i in range(1, 4): # Create 3 lag features (t-1, t-2, t-3)\n",
    "    df_master[f'sp500_lag_{i}'] = df_master['sp500_Close'].shift(i)\n",
    "\n",
    "# --- Label Crisis Periods ---\n",
    "# Define crisis periods (start_date, end_date)\n",
    "# Using dates from your proposal [cite: 351, 402]\n",
    "crisis_periods = {\n",
    "    '2015_China_Market_Crash': ('2015-06-15', '2016-02-11'),\n",
    "    '2018_Volatility': ('2018-10-01', '2018-12-31'),\n",
    "    'COVID_Crash': ('2020-02-19', '2020-03-23'),\n",
    "    '2022_Inflation_Crash': ('2022-01-01', '2022-12-31')\n",
    "}\n",
    "\n",
    "# Create the 'is_crisis' column, initialized to 0\n",
    "df_master['is_crisis'] = 0\n",
    "\n",
    "for crisis, (start, end) in crisis_periods.items():\n",
    "    df_master.loc[start:end, 'is_crisis'] = 1\n",
    "\n",
    "# Clean up by dropping initial rows with NaNs from lags/MA\n",
    "df_master.dropna(inplace=True)\n",
    "\n",
    "print(\"‚úÖ Time-series and crisis features added!\")\n",
    "print(\"Number of crisis days labeled:\", df_master['is_crisis'].sum())\n",
    "\n",
    "# Show comprehensive date range information\n",
    "print(f\"\\nüìÖ FULL DATASET DATE RANGE:\")\n",
    "print(f\"   Start: {df_master.index.min().strftime('%Y-%m-%d')}\")\n",
    "print(f\"   End: {df_master.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"   Total days: {len(df_master):,}\")\n",
    "\n",
    "# Show first and last few rows to confirm full range\n",
    "print(f\"\\nüîç FIRST 3 ROWS (earliest dates):\")\n",
    "print(df_master[['sp500_Close', 'is_crisis']].head(3))\n",
    "\n",
    "print(f\"\\nüîç LAST 3 ROWS (latest dates):\")\n",
    "print(df_master[['sp500_Close', 'is_crisis']].tail(3))\n",
    "\n",
    "# Show crisis period breakdown\n",
    "print(f\"\\nüìä CRISIS PERIOD BREAKDOWN:\")\n",
    "for crisis, (start, end) in crisis_periods.items():\n",
    "    crisis_data = df_master.loc[start:end] if start in df_master.index and end in df_master.index else pd.DataFrame()\n",
    "    crisis_count = len(crisis_data)\n",
    "    print(f\"   {crisis}: {crisis_count} days ({start} to {end})\")\n",
    "\n",
    "print(f\"\\nüìà TOTAL CRISIS vs NON-CRISIS DAYS:\")\n",
    "crisis_counts = df_master['is_crisis'].value_counts()\n",
    "print(f\"   Non-Crisis (0): {crisis_counts.get(0, 0):,} days\")\n",
    "print(f\"   Crisis (1): {crisis_counts.get(1, 0):,} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e3bf53",
   "metadata": {},
   "source": [
    "## Data Normalization & Final Prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505023a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data successfully scaled!\n",
      "Shape of scaled data: (2519, 18)\n",
      "\n",
      "Sample of scaled data:\n",
      "            sp500_Open  sp500_High  sp500_Low  sp500_Close  sp500_Volume  \\\n",
      "Date                                                                       \n",
      "2015-06-24    0.066572    0.063666   0.068382     0.063873      0.310978   \n",
      "2015-06-25    0.063432    0.061592   0.066824     0.062440      0.322218   \n",
      "2015-06-26    0.061748    0.059962   0.065358     0.062253      0.503730   \n",
      "2015-06-29    0.060833    0.057607   0.056483     0.052232      0.368762   \n",
      "2015-06-30    0.052246    0.052032   0.056409     0.053482      0.408814   \n",
      "\n",
      "            nasdaq_Close  nasdaq_Volume  ftse100_Close  ftse100_Volume  \\\n",
      "Date                                                                     \n",
      "2015-06-24      0.053131       0.009885       0.475687        0.177667   \n",
      "2015-06-25      0.052497       0.009734       0.466178        0.174231   \n",
      "2015-06-26      0.050529       0.033634       0.452274        0.158796   \n",
      "2015-06-29      0.042951       0.014139       0.418042        0.202789   \n",
      "2015-06-30      0.044714       0.014234       0.392470        0.234558   \n",
      "\n",
      "            macro_inflation  macro_unemployment  macro_vix  sp500_ma_7  \\\n",
      "Date                                                                     \n",
      "2015-06-24         0.003856            0.159292   0.056016    0.059116   \n",
      "2015-06-25         0.003856            0.159292   0.066213    0.059318   \n",
      "2015-06-26         0.003856            0.159292   0.066349    0.059354   \n",
      "2015-06-29         0.003856            0.159292   0.132019    0.057213   \n",
      "2015-06-30         0.003856            0.159292   0.123589    0.055636   \n",
      "\n",
      "            sp500_ma_30  sp500_lag_1  sp500_lag_2  sp500_lag_3  is_crisis  \n",
      "Date                                                                       \n",
      "2015-06-24     0.051495     0.067938     0.068080     0.065100          1  \n",
      "2015-06-25     0.051526     0.064342     0.068393     0.068080          1  \n",
      "2015-06-26     0.051368     0.062898     0.064773     0.068393          1  \n",
      "2015-06-29     0.050845     0.062710     0.063320     0.064773          1  \n",
      "2015-06-30     0.050314     0.052615     0.063130     0.063320          1  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# This assumes your fully-featured dataframe is named df_master\n",
    "\n",
    "# Separate the target variable and the crisis flag\n",
    "is_crisis_col = df_master['is_crisis']\n",
    "# We scale features, not the crisis flag itself\n",
    "features_to_scale = df_master.drop(columns=['is_crisis'])\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "scaled_features = scaler.fit_transform(features_to_scale)\n",
    "\n",
    "# Create a new DataFrame with the scaled features\n",
    "df_scaled = pd.DataFrame(scaled_features, index=df_master.index, columns=features_to_scale.columns)\n",
    "\n",
    "# Add the 'is_crisis' column back to the scaled DataFrame\n",
    "df_scaled['is_crisis'] = is_crisis_col\n",
    "\n",
    "print(\"‚úÖ Data successfully scaled!\")\n",
    "print(\"Shape of scaled data:\", df_scaled.shape)\n",
    "print(\"\\nSample of scaled data:\")\n",
    "print(df_scaled.head())\n",
    "\n",
    "df_scaled.to_csv('data/final_model_ready_data_only_timeSeries.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
