{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8810b8e",
   "metadata": {},
   "source": [
    "## Consolidate Financial and Macroeconomic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcff6b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Master DataFrame created successfully!\n",
      "Shape of the data: (331, 13)\n",
      "\n",
      "Column names:\n",
      "['sp500_Open', 'sp500_High', 'sp500_Low', 'sp500_Close', 'sp500_Volume', 'nasdaq_Close', 'nasdaq_Volume', 'ftse100_Close', 'ftse100_Volume', 'macro_gdp', 'macro_inflation', 'macro_unemployment', 'macro_vix']\n",
      "\n",
      "First 5 rows:\n",
      "             sp500_Open   sp500_High    sp500_Low  sp500_Close  sp500_Volume  \\\n",
      "Date                                                                           \n",
      "2024-04-01  5257.970215  5263.950195  5229.200195  5243.770020    3325930000   \n",
      "2024-04-02  5204.290039  5208.339844  5184.049805  5205.810059    3886590000   \n",
      "2024-04-03  5194.370117  5228.750000  5194.370117  5211.490234    3703250000   \n",
      "2024-04-04  5244.049805  5256.589844  5146.060059  5147.209961    4075680000   \n",
      "2024-04-05  5158.950195  5222.180176  5157.209961  5204.339844    3386780000   \n",
      "\n",
      "            nasdaq_Close  nasdaq_Volume  ftse100_Close  ftse100_Volume  \\\n",
      "Date                                                                     \n",
      "2024-04-01  16396.830078     4798390000    7938.600098    1.111398e+09   \n",
      "2024-04-02  16240.450195     4710280000    7935.100098    1.126450e+09   \n",
      "2024-04-03  16277.459961     5151500000    7937.399902    1.131677e+09   \n",
      "2024-04-04  16049.080078     5368700000    7975.899902    1.138496e+09   \n",
      "2024-04-05  16248.519531     4578130000    7911.200195    9.515091e+08   \n",
      "\n",
      "            macro_gdp  macro_inflation  macro_unemployment  macro_vix  \n",
      "Date                                                                   \n",
      "2024-04-01  29016.714          313.016                 3.9      13.65  \n",
      "2024-04-02  29016.714          313.016                 3.9      14.61  \n",
      "2024-04-03  29016.714          313.016                 3.9      14.33  \n",
      "2024-04-04  29016.714          313.016                 3.9      16.35  \n",
      "2024-04-05  29016.714          313.016                 3.9      16.03  \n",
      "\n",
      "Last 5 rows:\n",
      "             sp500_Open   sp500_High    sp500_Low  sp500_Close  sp500_Volume  \\\n",
      "Date                                                                           \n",
      "2025-07-21  6304.740234  6336.080078  6303.790039  6305.600098    5010840000   \n",
      "2025-07-22  6306.600098  6316.120117  6281.709961  6309.620117    5662040000   \n",
      "2025-07-23  6326.899902  6360.640137  6317.490234  6358.910156    5642510000   \n",
      "2025-07-24  6368.600098  6381.310059  6360.569824  6363.350098    5282720000   \n",
      "2025-07-25  6370.009766  6395.819824  6368.529785  6388.640137    4470720000   \n",
      "\n",
      "            nasdaq_Close  nasdaq_Volume  ftse100_Close  ftse100_Volume  \\\n",
      "Date                                                                     \n",
      "2025-07-21  20974.179688    12046970000    9013.000000    7.707727e+08   \n",
      "2025-07-22  20892.689453    10583710000    9023.799805    6.374148e+08   \n",
      "2025-07-23  21020.019531    10972770000    9061.500000    7.167808e+08   \n",
      "2025-07-24  21057.960938    12741070000    9138.400391    8.007222e+08   \n",
      "2025-07-25  21108.320312    11028310000    9120.299805    1.064164e+09   \n",
      "\n",
      "            macro_gdp  macro_inflation  macro_unemployment  macro_vix  \n",
      "Date                                                                   \n",
      "2025-07-21  29723.864           320.58                 4.2      16.65  \n",
      "2025-07-22  29723.864           320.58                 4.2      16.50  \n",
      "2025-07-23  29723.864           320.58                 4.2      15.37  \n",
      "2025-07-24  29723.864           320.58                 4.2      15.39  \n",
      "2025-07-25  29723.864           320.58                 4.2      15.39  \n",
      "\n",
      "Data types:\n",
      "sp500_Open            float64\n",
      "sp500_High            float64\n",
      "sp500_Low             float64\n",
      "sp500_Close           float64\n",
      "sp500_Volume            int64\n",
      "nasdaq_Close          float64\n",
      "nasdaq_Volume           int64\n",
      "ftse100_Close         float64\n",
      "ftse100_Volume        float64\n",
      "macro_gdp             float64\n",
      "macro_inflation       float64\n",
      "macro_unemployment    float64\n",
      "macro_vix             float64\n",
      "dtype: object\n",
      "\n",
      "Date range:\n",
      "From: 2024-04-01 00:00:00 To: 2025-07-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_FOLDER = \"test\"\n",
    "FINANCIAL_FILES = {\n",
    "    'sp500': os.path.join(DATA_FOLDER, 's&p_500_daily.csv'),\n",
    "    'nasdaq': os.path.join(DATA_FOLDER, 'nasdaq_daily.csv'),\n",
    "    'ftse100': os.path.join(DATA_FOLDER, 'ftse_100_daily.csv')\n",
    "}\n",
    "MACRO_FILES = {\n",
    "    'gdp': os.path.join(DATA_FOLDER, 'macro_gdp.csv'),\n",
    "    'inflation': os.path.join(DATA_FOLDER, 'macro_inflation_cpi.csv'),\n",
    "    'unemployment': os.path.join(DATA_FOLDER, 'macro_unemploymentrate.csv'),\n",
    "    'vix': os.path.join(DATA_FOLDER, 'macro_vix.csv')\n",
    "}\n",
    "\n",
    "# --- Load and Combine Data ---\n",
    "\n",
    "# Load the primary financial index (e.g., S&P 500)\n",
    "# The CSV structure: Row 1=headers, Row 2=tickers, Row 3=Date placeholder, Row 4+=data\n",
    "# We need to skip rows 1 and 2, then use column 0 (Price) as the date index\n",
    "df_master = pd.read_csv(FINANCIAL_FILES['sp500'], skiprows=[1, 2], index_col=0, parse_dates=True)\n",
    "\n",
    "# Rename the index to something more meaningful\n",
    "df_master.index.name = 'Date'\n",
    "\n",
    "# Select and rename key columns to avoid confusion\n",
    "df_master = df_master[['Open', 'High', 'Low', 'Close', 'Volume']].add_prefix('sp500_')\n",
    "\n",
    "# Load and merge other financial indices\n",
    "for name, path in FINANCIAL_FILES.items():\n",
    "    if name != 'sp500':\n",
    "        df_temp = pd.read_csv(path, skiprows=[1, 2], index_col=0, parse_dates=True)\n",
    "        df_temp.index.name = 'Date'\n",
    "        df_master = df_master.merge(\n",
    "            df_temp[['Close', 'Volume']].add_prefix(f'{name}_'),\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "# Load and merge macroeconomic data\n",
    "for name, path in MACRO_FILES.items():\n",
    "    try:\n",
    "        df_macro = pd.read_csv(path, index_col='DATE', parse_dates=True)\n",
    "        # Rename the column to be specific\n",
    "        df_macro.rename(columns={df_macro.columns[0]: f'macro_{name}'}, inplace=True)\n",
    "        df_master = df_master.merge(df_macro, left_index=True, right_index=True, how='left')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {path} not found, skipping {name} data\")\n",
    "\n",
    "# --- Clean and Preprocess ---\n",
    "\n",
    "# Forward-fill the macroeconomic data to fill daily gaps\n",
    "macro_cols = [col for col in df_master.columns if 'macro_' in col]\n",
    "if macro_cols:\n",
    "    df_master[macro_cols] = df_master[macro_cols].ffill()\n",
    "\n",
    "# Use interpolation for any remaining gaps (e.g., in stock data on holidays)\n",
    "df_master.interpolate(method='time', inplace=True)\n",
    "\n",
    "# Drop any rows that still have missing values (typically at the very beginning)\n",
    "df_master.dropna(inplace=True)\n",
    "\n",
    "print(\"‚úÖ Master DataFrame created successfully!\")\n",
    "print(\"Shape of the data:\", df_master.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(df_master.columns.tolist())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_master.head())\n",
    "print(\"\\nLast 5 rows:\")\n",
    "print(df_master.tail())\n",
    "print(\"\\nData types:\")\n",
    "print(df_master.dtypes)\n",
    "print(\"\\nDate range:\")\n",
    "print(f\"From: {df_master.index.min()} To: {df_master.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63d218",
   "metadata": {},
   "source": [
    "## Process GDELT Data to Create Sentiment Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3217379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GDELT data from test/gdelt_usa_10year_raw.csv...\n",
      "GDELT data shape: (16202, 37)\n",
      "Daily sentiment shape: (521, 1)\n",
      "Daily sentiment date range: 2024-01-01 00:00:00 to 2025-06-12 00:00:00\n",
      "Master DataFrame shape before merge: (331, 13)\n",
      "Master DataFrame shape after merge: (331, 14)\n",
      "‚úÖ GDELT sentiment successfully merged into master DataFrame!\n",
      "Final shape: (331, 14)\n",
      "\n",
      "Column names:\n",
      "['sp500_Open', 'sp500_High', 'sp500_Low', 'sp500_Close', 'sp500_Volume', 'nasdaq_Close', 'nasdaq_Volume', 'ftse100_Close', 'ftse100_Volume', 'macro_gdp', 'macro_inflation', 'macro_unemployment', 'macro_vix', 'gdelt_sentiment']\n",
      "\n",
      "Sample data with sentiment:\n",
      "            sp500_Close  gdelt_sentiment\n",
      "Date                                    \n",
      "2025-07-21  6305.600098        -2.529748\n",
      "2025-07-22  6309.620117        -2.529748\n",
      "2025-07-23  6358.910156        -2.529748\n",
      "2025-07-24  6363.350098        -2.529748\n",
      "2025-07-25  6388.640137        -2.529748\n",
      "\n",
      "Sentiment statistics:\n",
      "Mean: -2.333\n",
      "Std: 0.777\n",
      "Min: -4.677\n",
      "Max: 2.809\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load GDELT Data ---\n",
    "gdelt_path = 'test/gdelt_usa_10year_raw.csv'\n",
    "print(f\"Loading GDELT data from {gdelt_path}...\")\n",
    "df_gdelt = pd.read_csv(gdelt_path)\n",
    "\n",
    "print(f\"GDELT data shape: {df_gdelt.shape}\")\n",
    "\n",
    "# --- Parse Sentiment from V2Tone ---\n",
    "def parse_v2tone_quick(v2tone_str):\n",
    "    \"\"\"A robust function to parse the V2Tone string.\"\"\"\n",
    "    try:\n",
    "        # The first value is the average tone\n",
    "        return float(str(v2tone_str).split(',')[0])\n",
    "    except (ValueError, IndexError):\n",
    "        return np.nan # Return NaN if parsing fails\n",
    "\n",
    "df_gdelt['tone_avg'] = df_gdelt['V2Tone'].apply(parse_v2tone_quick)\n",
    "\n",
    "# --- Aggregate Sentiment by Day ---\n",
    "# Convert DATE column to datetime objects\n",
    "df_gdelt['date_only'] = pd.to_datetime(df_gdelt['DATE'], format='%Y%m%d%H%M%S').dt.date\n",
    "\n",
    "# Calculate the mean sentiment for each day\n",
    "daily_sentiment = df_gdelt.groupby('date_only')['tone_avg'].mean().to_frame(name='gdelt_sentiment')\n",
    "daily_sentiment.index = pd.to_datetime(daily_sentiment.index)\n",
    "\n",
    "print(f\"Daily sentiment shape: {daily_sentiment.shape}\")\n",
    "print(f\"Daily sentiment date range: {daily_sentiment.index.min()} to {daily_sentiment.index.max()}\")\n",
    "\n",
    "# --- Clean existing sentiment columns if they exist ---\n",
    "sentiment_cols = [col for col in df_master.columns if 'gdelt_sentiment' in col]\n",
    "if sentiment_cols:\n",
    "    print(f\"Removing existing sentiment columns: {sentiment_cols}\")\n",
    "    df_master = df_master.drop(columns=sentiment_cols)\n",
    "\n",
    "# --- Merge into Master DataFrame ---\n",
    "print(f\"Master DataFrame shape before merge: {df_master.shape}\")\n",
    "df_master = df_master.merge(daily_sentiment, left_index=True, right_index=True, how='left')\n",
    "print(f\"Master DataFrame shape after merge: {df_master.shape}\")\n",
    "\n",
    "# Fill weekends/holidays with the last known sentiment value\n",
    "df_master['gdelt_sentiment'] = df_master['gdelt_sentiment'].ffill()\n",
    "\n",
    "# Fill any remaining initial NaNs with 0 (neutral)\n",
    "df_master['gdelt_sentiment'] = df_master['gdelt_sentiment'].fillna(0)\n",
    "\n",
    "print(\"‚úÖ GDELT sentiment successfully merged into master DataFrame!\")\n",
    "print(\"Final shape:\", df_master.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(df_master.columns.tolist())\n",
    "print(\"\\nSample data with sentiment:\")\n",
    "print(df_master[['sp500_Close', 'gdelt_sentiment']].tail())\n",
    "print(f\"\\nSentiment statistics:\")\n",
    "print(f\"Mean: {df_master['gdelt_sentiment'].mean():.3f}\")\n",
    "print(f\"Std: {df_master['gdelt_sentiment'].std():.3f}\")\n",
    "print(f\"Min: {df_master['gdelt_sentiment'].min():.3f}\")\n",
    "print(f\"Max: {df_master['gdelt_sentiment'].max():.3f}\")\n",
    "print(f\"Missing values: {df_master['gdelt_sentiment'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adf4df9",
   "metadata": {},
   "source": [
    "## Final Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae7a0b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL DATASET SUMMARY\n",
      "============================================================\n",
      "üìä Dataset Shape: 331 rows √ó 14 columns\n",
      "üìÖ Date Range: 2024-04-01 to 2025-07-25\n",
      "‚è±Ô∏è  Duration: 480 days\n",
      "\n",
      "üìà Data Categories:\n",
      "  ‚Ä¢ Financial Data: 9 columns\n",
      "  ‚Ä¢ Macroeconomic Data: 4 columns\n",
      "  ‚Ä¢ Sentiment Data: 1 columns\n",
      "\n",
      "üîç Data Quality Check:\n",
      "  ‚Ä¢ Total missing values: 0\n",
      "  ‚Ä¢ Rows with any missing values: 0\n",
      "\n",
      "üìã Column Summary:\n",
      "   1. sp500_Open           - Missing:    0 (0.0%)\n",
      "   2. sp500_High           - Missing:    0 (0.0%)\n",
      "   3. sp500_Low            - Missing:    0 (0.0%)\n",
      "   4. sp500_Close          - Missing:    0 (0.0%)\n",
      "   5. sp500_Volume         - Missing:    0 (0.0%)\n",
      "   6. nasdaq_Close         - Missing:    0 (0.0%)\n",
      "   7. nasdaq_Volume        - Missing:    0 (0.0%)\n",
      "   8. ftse100_Close        - Missing:    0 (0.0%)\n",
      "   9. ftse100_Volume       - Missing:    0 (0.0%)\n",
      "  10. macro_gdp            - Missing:    0 (0.0%)\n",
      "  11. macro_inflation      - Missing:    0 (0.0%)\n",
      "  12. macro_unemployment   - Missing:    0 (0.0%)\n",
      "  13. macro_vix            - Missing:    0 (0.0%)\n",
      "  14. gdelt_sentiment      - Missing:    0 (0.0%)\n",
      "\n",
      "‚úÖ Dataset is ready for modeling and analysis!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final verification and summary of the consolidated dataset\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"üìä Dataset Shape: {df_master.shape[0]:,} rows √ó {df_master.shape[1]} columns\")\n",
    "print(f\"üìÖ Date Range: {df_master.index.min().strftime('%Y-%m-%d')} to {df_master.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"‚è±Ô∏è  Duration: {(df_master.index.max() - df_master.index.min()).days:,} days\")\n",
    "\n",
    "print(\"\\nüìà Data Categories:\")\n",
    "financial_cols = [col for col in df_master.columns if any(x in col for x in ['sp500', 'nasdaq', 'ftse'])]\n",
    "macro_cols = [col for col in df_master.columns if 'macro_' in col]\n",
    "sentiment_cols = [col for col in df_master.columns if 'gdelt' in col]\n",
    "\n",
    "print(f\"  ‚Ä¢ Financial Data: {len(financial_cols)} columns\")\n",
    "print(f\"  ‚Ä¢ Macroeconomic Data: {len(macro_cols)} columns\") \n",
    "print(f\"  ‚Ä¢ Sentiment Data: {len(sentiment_cols)} columns\")\n",
    "\n",
    "print(\"\\nüîç Data Quality Check:\")\n",
    "print(f\"  ‚Ä¢ Total missing values: {df_master.isnull().sum().sum()}\")\n",
    "print(f\"  ‚Ä¢ Rows with any missing values: {df_master.isnull().any(axis=1).sum()}\")\n",
    "\n",
    "print(\"\\nüìã Column Summary:\")\n",
    "for i, col in enumerate(df_master.columns, 1):\n",
    "    missing = df_master[col].isnull().sum()\n",
    "    print(f\"  {i:2}. {col:<20} - Missing: {missing:4} ({missing/len(df_master)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset is ready for modeling and analysis!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb20557b",
   "metadata": {},
   "source": [
    "## Create Time-Series & Crisis Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaec9906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Time-series and crisis features added!\n",
      "Number of crisis days labeled: 0\n",
      "\n",
      "üìÖ FULL DATASET DATE RANGE:\n",
      "   Start: 2024-05-10\n",
      "   End: 2025-07-25\n",
      "   Total days: 302\n",
      "\n",
      "üîç FIRST 3 ROWS (earliest dates):\n",
      "            sp500_Close  is_crisis\n",
      "Date                              \n",
      "2024-05-10  5222.680176          0\n",
      "2024-05-13  5221.419922          0\n",
      "2024-05-14  5246.680176          0\n",
      "\n",
      "üîç LAST 3 ROWS (latest dates):\n",
      "            sp500_Close  is_crisis\n",
      "Date                              \n",
      "2025-07-23  6358.910156          0\n",
      "2025-07-24  6363.350098          0\n",
      "2025-07-25  6388.640137          0\n",
      "\n",
      "üìä CRISIS PERIOD BREAKDOWN:\n",
      "   2015_China_Market_Crash: 0 days (2015-06-15 to 2016-02-11)\n",
      "   2018_Volatility: 0 days (2018-10-01 to 2018-12-31)\n",
      "   COVID_Crash: 0 days (2020-02-19 to 2020-03-23)\n",
      "   2022_Inflation_Crash: 0 days (2022-01-01 to 2022-12-31)\n",
      "\n",
      "üìà TOTAL CRISIS vs NON-CRISIS DAYS:\n",
      "   Non-Crisis (0): 302 days\n",
      "   Crisis (1): 0 days\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This assumes your master dataframe is named df_master\n",
    "\n",
    "# --- Create Time-Series Features ---\n",
    "# Moving Averages for the S&P 500 close price\n",
    "df_master['sp500_ma_7'] = df_master['sp500_Close'].rolling(window=7).mean()\n",
    "df_master['sp500_ma_30'] = df_master['sp500_Close'].rolling(window=30).mean()\n",
    "\n",
    "# Lagged Values for the S&P 500 close price\n",
    "for i in range(1, 4): # Create 3 lag features (t-1, t-2, t-3)\n",
    "    df_master[f'sp500_lag_{i}'] = df_master['sp500_Close'].shift(i)\n",
    "\n",
    "# --- Label Crisis Periods ---\n",
    "# Define crisis periods (start_date, end_date)\n",
    "# Using dates from your proposal [cite: 351, 402]\n",
    "crisis_periods = {\n",
    "    '2015_China_Market_Crash': ('2015-06-15', '2016-02-11'),\n",
    "    '2018_Volatility': ('2018-10-01', '2018-12-31'),\n",
    "    'COVID_Crash': ('2020-02-19', '2020-03-23'),\n",
    "    '2022_Inflation_Crash': ('2022-01-01', '2022-12-31')\n",
    "}\n",
    "\n",
    "# Create the 'is_crisis' column, initialized to 0\n",
    "df_master['is_crisis'] = 0\n",
    "\n",
    "for crisis, (start, end) in crisis_periods.items():\n",
    "    df_master.loc[start:end, 'is_crisis'] = 1\n",
    "\n",
    "# Clean up by dropping initial rows with NaNs from lags/MA\n",
    "df_master.dropna(inplace=True)\n",
    "\n",
    "print(\"‚úÖ Time-series and crisis features added!\")\n",
    "print(\"Number of crisis days labeled:\", df_master['is_crisis'].sum())\n",
    "\n",
    "# Show comprehensive date range information\n",
    "print(f\"\\nüìÖ FULL DATASET DATE RANGE:\")\n",
    "print(f\"   Start: {df_master.index.min().strftime('%Y-%m-%d')}\")\n",
    "print(f\"   End: {df_master.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"   Total days: {len(df_master):,}\")\n",
    "\n",
    "# Show first and last few rows to confirm full range\n",
    "print(f\"\\nüîç FIRST 3 ROWS (earliest dates):\")\n",
    "print(df_master[['sp500_Close', 'is_crisis']].head(3))\n",
    "\n",
    "print(f\"\\nüîç LAST 3 ROWS (latest dates):\")\n",
    "print(df_master[['sp500_Close', 'is_crisis']].tail(3))\n",
    "\n",
    "# Show crisis period breakdown\n",
    "print(f\"\\nüìä CRISIS PERIOD BREAKDOWN:\")\n",
    "for crisis, (start, end) in crisis_periods.items():\n",
    "    crisis_data = df_master.loc[start:end] if start in df_master.index and end in df_master.index else pd.DataFrame()\n",
    "    crisis_count = len(crisis_data)\n",
    "    print(f\"   {crisis}: {crisis_count} days ({start} to {end})\")\n",
    "\n",
    "print(f\"\\nüìà TOTAL CRISIS vs NON-CRISIS DAYS:\")\n",
    "crisis_counts = df_master['is_crisis'].value_counts()\n",
    "print(f\"   Non-Crisis (0): {crisis_counts.get(0, 0):,} days\")\n",
    "print(f\"   Crisis (1): {crisis_counts.get(1, 0):,} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e3bf53",
   "metadata": {},
   "source": [
    "## Data Normalization & Final Prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5505023a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data successfully scaled!\n",
      "Shape of scaled data: (302, 20)\n",
      "\n",
      "Sample of scaled data:\n",
      "            sp500_Open  sp500_High  sp500_Low  sp500_Close  sp500_Volume  \\\n",
      "Date                                                                       \n",
      "2024-05-10    0.191849    0.005779   0.244306     0.170649      0.240586   \n",
      "2024-05-13    0.197208    0.003715   0.245271     0.169752      0.323077   \n",
      "2024-05-14    0.188749    0.014989   0.249718     0.187720      0.388762   \n",
      "2024-05-15    0.218518    0.067780   0.279245     0.231444      0.336670   \n",
      "2024-05-16    0.251571    0.079587   0.300719     0.223584      0.266397   \n",
      "\n",
      "            nasdaq_Close  nasdaq_Volume  ftse100_Close  ftse100_Volume  \\\n",
      "Date                                                                     \n",
      "2024-05-10      0.183713       0.007624       0.517033        0.312141   \n",
      "2024-05-13      0.191824       0.008185       0.504147        0.435782   \n",
      "2024-05-14      0.212874       0.039400       0.513126        0.518928   \n",
      "2024-05-15      0.252462       0.053457       0.525258        0.497399   \n",
      "2024-05-16      0.244916       0.091055       0.520392        0.397772   \n",
      "\n",
      "            macro_gdp  macro_inflation  macro_unemployment  macro_vix  \\\n",
      "Date                                                                    \n",
      "2024-05-10        0.0              0.0                 0.0   0.017050   \n",
      "2024-05-13        0.0              0.0                 0.0   0.042995   \n",
      "2024-05-14        0.0              0.0                 0.0   0.038547   \n",
      "2024-05-15        0.0              0.0                 0.0   0.014579   \n",
      "2024-05-16        0.0              0.0                 0.0   0.013837   \n",
      "\n",
      "            gdelt_sentiment  sp500_ma_7  sp500_ma_30  sp500_lag_1  \\\n",
      "Date                                                                \n",
      "2024-05-10         0.304302    0.000000     0.000696     0.167546   \n",
      "2024-05-13         0.164027    0.019325     0.000000     0.173775   \n",
      "2024-05-14         0.065397    0.033939     0.001272     0.172862   \n",
      "2024-05-15         0.257213    0.049600     0.004282     0.191159   \n",
      "2024-05-16         0.291009    0.063048     0.008948     0.235683   \n",
      "\n",
      "            sp500_lag_2  sp500_lag_3  is_crisis  \n",
      "Date                                             \n",
      "2024-05-10     0.148895     0.154449          0  \n",
      "2024-05-13     0.168086     0.154426          0  \n",
      "2024-05-14     0.174336     0.174330          0  \n",
      "2024-05-15     0.173420     0.180812          0  \n",
      "2024-05-16     0.191776     0.179862          0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# This assumes your fully-featured dataframe is named df_master\n",
    "\n",
    "# Separate the target variable and the crisis flag\n",
    "is_crisis_col = df_master['is_crisis']\n",
    "# We scale features, not the crisis flag itself\n",
    "features_to_scale = df_master.drop(columns=['is_crisis'])\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "scaled_features = scaler.fit_transform(features_to_scale)\n",
    "\n",
    "# Create a new DataFrame with the scaled features\n",
    "df_scaled = pd.DataFrame(scaled_features, index=df_master.index, columns=features_to_scale.columns)\n",
    "\n",
    "# Add the 'is_crisis' column back to the scaled DataFrame\n",
    "df_scaled['is_crisis'] = is_crisis_col\n",
    "\n",
    "print(\"‚úÖ Data successfully scaled!\")\n",
    "print(\"Shape of scaled data:\", df_scaled.shape)\n",
    "print(\"\\nSample of scaled data:\")\n",
    "print(df_scaled.head())\n",
    "\n",
    "df_scaled.to_csv('test/usa_forward_test_processed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dfb6c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ Starting Local Preprocessing of Fresh US Data (2024-2025) ---\n",
      "\n",
      "Step 1: Loading and merging financial and macroeconomic data...\n",
      "‚úÖ Financial and Macro data successfully combined.\n",
      "\n",
      "Step 2: Processing and merging GDELT sentiment data...\n",
      "‚úÖ GDELT sentiment data successfully merged.\n",
      "\n",
      "Step 3: Creating time-series features (moving averages and lags)...\n",
      "‚úÖ Time-series features successfully added.\n",
      "\n",
      "--- üéâ Preprocessing Complete! ---\n",
      "‚úÖ Your model-ready data has been saved as: 'test/usa_forward_test_processed.csv'\n",
      "Final data shape: (302, 19)\n",
      "\n",
      "Sample of the final processed data:\n",
      "             sp500_Open   sp500_High    sp500_Low  sp500_Close  sp500_Volume  \\\n",
      "Date                                                                           \n",
      "2024-05-10  5225.490234  5239.660156  5209.680176  5222.680176    3617900000   \n",
      "2024-05-13  5233.080078  5237.259766  5211.160156  5221.419922    4255710000   \n",
      "2024-05-14  5221.100098  5250.370117  5217.979980  5246.680176    4763580000   \n",
      "2024-05-15  5263.259766  5311.759766  5263.259766  5308.149902    4360810000   \n",
      "2024-05-16  5310.069824  5325.490234  5296.189941  5297.100098    3817470000   \n",
      "\n",
      "            nasdaq_Close  nasdaq_Volume  ftse100_Close  ftse100_Volume  \\\n",
      "Date                                                                     \n",
      "2024-05-10  16340.870117     4402110000    8433.799805    6.982222e+08   \n",
      "2024-05-13  16388.240234     4452750000    8415.000000    9.747915e+08   \n",
      "2024-05-14  16511.179688     7270240000    8428.099609    1.160779e+09   \n",
      "2024-05-15  16742.390625     8538990000    8445.799805    1.112621e+09   \n",
      "2024-05-16  16698.320312    11932600000    8438.700195    8.897669e+08   \n",
      "\n",
      "            macro_gdp  macro_inflation  macro_unemployment  macro_vix  \\\n",
      "Date                                                                    \n",
      "2024-05-10  29016.714           313.14                 4.0      12.55   \n",
      "2024-05-13  29016.714           313.14                 4.0      13.60   \n",
      "2024-05-14  29016.714           313.14                 4.0      13.42   \n",
      "2024-05-15  29016.714           313.14                 4.0      12.45   \n",
      "2024-05-16  29016.714           313.14                 4.0      12.42   \n",
      "\n",
      "            gdelt_sentiment   sp500_ma_7  sp500_ma_30  sp500_lag_1  \\\n",
      "Date                                                                 \n",
      "2024-05-10        -2.374688  5169.265834  5122.603044  5214.080078   \n",
      "2024-05-13        -3.419794  5191.725795  5121.858040  5222.680176   \n",
      "2024-05-14        -4.154618  5208.710100  5123.220378  5221.419922   \n",
      "2024-05-15        -2.725518  5226.911482  5126.442367  5246.680176   \n",
      "2024-05-16        -2.473728  5242.540039  5131.438704  5308.149902   \n",
      "\n",
      "            sp500_lag_2  sp500_lag_3  \n",
      "Date                                  \n",
      "2024-05-10  5187.669922  5187.700195  \n",
      "2024-05-13  5214.080078  5187.669922  \n",
      "2024-05-14  5222.680176  5214.080078  \n",
      "2024-05-15  5221.419922  5222.680176  \n",
      "2024-05-16  5246.680176  5221.419922  \n",
      "‚úÖ GDELT sentiment data successfully merged.\n",
      "\n",
      "Step 3: Creating time-series features (moving averages and lags)...\n",
      "‚úÖ Time-series features successfully added.\n",
      "\n",
      "--- üéâ Preprocessing Complete! ---\n",
      "‚úÖ Your model-ready data has been saved as: 'test/usa_forward_test_processed.csv'\n",
      "Final data shape: (302, 19)\n",
      "\n",
      "Sample of the final processed data:\n",
      "             sp500_Open   sp500_High    sp500_Low  sp500_Close  sp500_Volume  \\\n",
      "Date                                                                           \n",
      "2024-05-10  5225.490234  5239.660156  5209.680176  5222.680176    3617900000   \n",
      "2024-05-13  5233.080078  5237.259766  5211.160156  5221.419922    4255710000   \n",
      "2024-05-14  5221.100098  5250.370117  5217.979980  5246.680176    4763580000   \n",
      "2024-05-15  5263.259766  5311.759766  5263.259766  5308.149902    4360810000   \n",
      "2024-05-16  5310.069824  5325.490234  5296.189941  5297.100098    3817470000   \n",
      "\n",
      "            nasdaq_Close  nasdaq_Volume  ftse100_Close  ftse100_Volume  \\\n",
      "Date                                                                     \n",
      "2024-05-10  16340.870117     4402110000    8433.799805    6.982222e+08   \n",
      "2024-05-13  16388.240234     4452750000    8415.000000    9.747915e+08   \n",
      "2024-05-14  16511.179688     7270240000    8428.099609    1.160779e+09   \n",
      "2024-05-15  16742.390625     8538990000    8445.799805    1.112621e+09   \n",
      "2024-05-16  16698.320312    11932600000    8438.700195    8.897669e+08   \n",
      "\n",
      "            macro_gdp  macro_inflation  macro_unemployment  macro_vix  \\\n",
      "Date                                                                    \n",
      "2024-05-10  29016.714           313.14                 4.0      12.55   \n",
      "2024-05-13  29016.714           313.14                 4.0      13.60   \n",
      "2024-05-14  29016.714           313.14                 4.0      13.42   \n",
      "2024-05-15  29016.714           313.14                 4.0      12.45   \n",
      "2024-05-16  29016.714           313.14                 4.0      12.42   \n",
      "\n",
      "            gdelt_sentiment   sp500_ma_7  sp500_ma_30  sp500_lag_1  \\\n",
      "Date                                                                 \n",
      "2024-05-10        -2.374688  5169.265834  5122.603044  5214.080078   \n",
      "2024-05-13        -3.419794  5191.725795  5121.858040  5222.680176   \n",
      "2024-05-14        -4.154618  5208.710100  5123.220378  5221.419922   \n",
      "2024-05-15        -2.725518  5226.911482  5126.442367  5246.680176   \n",
      "2024-05-16        -2.473728  5242.540039  5131.438704  5308.149902   \n",
      "\n",
      "            sp500_lag_2  sp500_lag_3  \n",
      "Date                                  \n",
      "2024-05-10  5187.669922  5187.700195  \n",
      "2024-05-13  5214.080078  5187.669922  \n",
      "2024-05-14  5222.680176  5214.080078  \n",
      "2024-05-15  5221.419922  5222.680176  \n",
      "2024-05-16  5246.680176  5221.419922  \n"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"--- üöÄ Starting Local Preprocessing of Fresh US Data (2024-2025) ---\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# Set this to the name of your folder containing the new raw data files.\n",
    "RAW_DATA_FOLDER = \"test\"\n",
    "\n",
    "# Define the paths to your new files\n",
    "FINANCIAL_FILES = {\n",
    "    'sp500': os.path.join(RAW_DATA_FOLDER, 's&p_500_daily.csv'),\n",
    "    'nasdaq': os.path.join(RAW_DATA_FOLDER, 'nasdaq_daily.csv'),\n",
    "    'ftse100': os.path.join(RAW_DATA_FOLDER, 'ftse_100_daily.csv')\n",
    "}\n",
    "MACRO_FILES = {\n",
    "    'gdp': os.path.join(RAW_DATA_FOLDER, 'macro_gdp.csv'),\n",
    "    'inflation': os.path.join(RAW_DATA_FOLDER, 'macro_inflation_cpi.csv'),\n",
    "    'unemployment': os.path.join(RAW_DATA_FOLDER, 'macro_unemploymentrate.csv'),\n",
    "    'vix': os.path.join(RAW_DATA_FOLDER, 'macro_vix.csv')\n",
    "}\n",
    "# Make sure your new GDELT file has this exact name inside the raw data folder\n",
    "GDELT_FILE = os.path.join(RAW_DATA_FOLDER, 'gdelt_usa_10year_raw.csv')\n",
    "\n",
    "\n",
    "# --- 1. Load and Combine Financial & Macro Data ---\n",
    "print(\"\\nStep 1: Loading and merging financial and macroeconomic data...\")\n",
    "try:\n",
    "    # Load S&P 500 as the base, handling the specific CSV structure\n",
    "    # Use the same format as earlier cells: skiprows=[1, 2] and index_col=0\n",
    "    df_master = pd.read_csv(FINANCIAL_FILES['sp500'], skiprows=[1, 2], index_col=0, parse_dates=True)\n",
    "    df_master.index.name = 'Date'\n",
    "    df_master = df_master[['Open', 'High', 'Low', 'Close', 'Volume']].add_prefix('sp500_')\n",
    "\n",
    "    # Merge other financial indices\n",
    "    for name, path in FINANCIAL_FILES.items():\n",
    "        if name != 'sp500':\n",
    "            df_temp = pd.read_csv(path, skiprows=[1, 2], index_col=0, parse_dates=True)\n",
    "            df_temp.index.name = 'Date'\n",
    "            df_master = df_master.merge(\n",
    "                df_temp[['Close', 'Volume']].add_prefix(f'{name}_'),\n",
    "                left_index=True, right_index=True, how='left'\n",
    "            )\n",
    "\n",
    "    # Merge macroeconomic data\n",
    "    for name, path in MACRO_FILES.items():\n",
    "        try:\n",
    "            df_macro = pd.read_csv(path, index_col='DATE', parse_dates=True)\n",
    "            df_macro.rename(columns={df_macro.columns[0]: f'macro_{name}'}, inplace=True)\n",
    "            df_master = df_master.merge(df_macro, left_index=True, right_index=True, how='left')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {path} not found, skipping {name} data\")\n",
    "\n",
    "    # Forward-fill macro data and interpolate any gaps\n",
    "    macro_cols = [col for col in df_master.columns if 'macro_' in col]\n",
    "    if macro_cols:\n",
    "        df_master[macro_cols] = df_master[macro_cols].ffill()\n",
    "    df_master.interpolate(method='time', inplace=True)\n",
    "    df_master.dropna(inplace=True)\n",
    "    print(\"‚úÖ Financial and Macro data successfully combined.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå ERROR: A required file was not found. Please check your file paths. Missing file: {e.filename}\")\n",
    "\n",
    "\n",
    "# --- 2. Process and Merge GDELT Sentiment Data ---\n",
    "print(\"\\nStep 2: Processing and merging GDELT sentiment data...\")\n",
    "try:\n",
    "    df_gdelt = pd.read_csv(GDELT_FILE)\n",
    "\n",
    "    def parse_v2tone_quick(v2tone_str):\n",
    "        try:\n",
    "            return float(str(v2tone_str).split(',')[0])\n",
    "        except (ValueError, IndexError):\n",
    "            return np.nan\n",
    "\n",
    "    df_gdelt['tone_avg'] = df_gdelt['V2Tone'].apply(parse_v2tone_quick)\n",
    "    df_gdelt['date_only'] = pd.to_datetime(df_gdelt['DATE'], format='%Y%m%d%H%M%S').dt.date\n",
    "    daily_sentiment = df_gdelt.groupby('date_only')['tone_avg'].mean().to_frame(name='gdelt_sentiment')\n",
    "    daily_sentiment.index = pd.to_datetime(daily_sentiment.index)\n",
    "\n",
    "    df_master = df_master.merge(daily_sentiment, left_index=True, right_index=True, how='left')\n",
    "    df_master['gdelt_sentiment'] = df_master['gdelt_sentiment'].ffill().fillna(0)\n",
    "    print(\"‚úÖ GDELT sentiment data successfully merged.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: GDELT file not found at '{GDELT_FILE}'. Please check the file path.\")\n",
    "\n",
    "\n",
    "# --- 3. Create Time-Series Features ---\n",
    "print(\"\\nStep 3: Creating time-series features (moving averages and lags)...\")\n",
    "df_master['sp500_ma_7'] = df_master['sp500_Close'].rolling(window=7).mean()\n",
    "df_master['sp500_ma_30'] = df_master['sp500_Close'].rolling(window=30).mean()\n",
    "for i in range(1, 4):\n",
    "    df_master[f'sp500_lag_{i}'] = df_master['sp500_Close'].shift(i)\n",
    "\n",
    "# Drop any rows with NaN values created by the feature engineering\n",
    "df_master.dropna(inplace=True)\n",
    "print(\"‚úÖ Time-series features successfully added.\")\n",
    "\n",
    "\n",
    "# --- 4. Save the Final Processed File ---\n",
    "FINAL_OUTPUT_FILE = 'test/usa_forward_test_processed.csv'\n",
    "df_master.to_csv(FINAL_OUTPUT_FILE)\n",
    "\n",
    "print(f\"\\n--- üéâ Preprocessing Complete! ---\")\n",
    "print(f\"‚úÖ Your model-ready data has been saved as: '{FINAL_OUTPUT_FILE}'\")\n",
    "print(f\"Final data shape: {df_master.shape}\")\n",
    "print(\"\\nSample of the final processed data:\")\n",
    "print(df_master.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e537dd9",
   "metadata": {},
   "source": [
    "## Visualize Key Relationships\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
